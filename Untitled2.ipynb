{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPe2Q2M9w92n60ZWmkm8NRh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R0maUr6iAtS6"},"outputs":[],"source":["pip install datasets"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizer\n","from datasets import load_dataset\n","\n","# IWSLT 데이터셋 로드\n","dataset = load_dataset(\"iwslt2017\", \"iwslt2017-ko-en\")\n","print(dataset)"],"metadata":{"id":"aQP8ia5wAyVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizer\n","from datasets import load_dataset\n","\n","# IWSLT 데이터셋 로드 (한국어-영어)\n","dataset = load_dataset(\"iwslt2017\", \"iwslt2017-en-ko\")\n","\n","# 토크나이저 정의\n","tokenizer_en = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","tokenizer_ko = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","# 배치 전처리 함수\n","def collate_fn(batch):\n","    src_batch = tokenizer_ko([item['translation']['ko'] for item in batch], padding=True, truncation=True, return_tensors=\"pt\")\n","    tgt_batch = tokenizer_en([item['translation']['en'] for item in batch], padding=True, truncation=True, return_tensors=\"pt\")\n","\n","    src_batch = src_batch.input_ids\n","    tgt_batch = tgt_batch.input_ids\n","\n","    return src_batch, tgt_batch\n","\n","# DataLoader 설정\n","train_loader = DataLoader(dataset['train'], batch_size=32, collate_fn=collate_fn, shuffle=True)\n","valid_loader = DataLoader(dataset['validation'], batch_size=32, collate_fn=collate_fn)\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, src):\n","        embedded = self.embedding(src)  # (batch_size, seq_len, emb_dim)\n","        outputs, hidden = self.rnn(embedded)  # (batch_size, seq_len, hidden_dim), (1, batch_size, hidden_dim)\n","        return hidden  # hidden: (1, batch_size, hidden_dim)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, input, hidden):\n","        input = input.unsqueeze(1)  # (batch_size, 1)\n","        embedded = self.embedding(input)  # (batch_size, 1, emb_dim)\n","        output, hidden = self.rnn(embedded, hidden)  # output: (batch_size, 1, hidden_dim)\n","        prediction = self.fc_out(output.squeeze(1))  # (batch_size, output_dim)\n","        return prediction, hidden\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, tgt):\n","        hidden = self.encoder(src)  # hidden: (1, batch_size, hidden_dim)\n","        outputs = []\n","\n","        input = tgt[0, :]  # 시작 토큰을 첫 번째로 사용\n","        for t in range(1, tgt.size(1)):  # 나머지 토큰에 대해 반복\n","            output, hidden = self.decoder(input, hidden)\n","            outputs.append(output)\n","            input = tgt[:, t]  # 다음 토큰을 입력으로 사용\n","\n","        return torch.stack(outputs, dim=1)  # (batch_size, seq_length, output_dim)\n","\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, tgt):\n","        # Encoder의 hidden state 얻기\n","        hidden = self.encoder(src)  # hidden: (1, batch_size, hidden_dim)\n","        batch_size = src.size(0)\n","        tgt_len = tgt.size(1)\n","        output_dim = self.decoder.fc_out.out_features\n","\n","        # 디코더의 출력을 저장할 텐서 초기화\n","        outputs = torch.zeros(batch_size, tgt_len - 1, output_dim).to(src.device)\n","\n","        # 첫 입력 토큰은 tgt의 첫 번째 토큰입니다 (보통 <sos>)\n","        input = tgt[:, 0]  # (batch_size)\n","\n","        for t in range(1, tgt_len):\n","            output, hidden = self.decoder(input, hidden)\n","            outputs[:, t - 1] = output\n","            input = tgt[:, t]  # 다음 입력 토큰 설정\n","\n","        return outputs\n","\n","\n","\n","# 하이퍼파라미터 설정\n","INPUT_DIM = len(tokenizer_ko)\n","OUTPUT_DIM = len(tokenizer_en)\n","EMB_DIM = 128\n","HIDDEN_DIM = 256\n","N_EPOCHS = 10\n","\n","# 모델 및 최적화기 초기화\n","encoder = Encoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM)\n","decoder = Decoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM)\n","model = Seq2Seq(encoder, decoder)\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss()\n","\n","# 모델 학습 함수\n","def train(model, iterator, optimizer, criterion):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for src, tgt in iterator:\n","        optimizer.zero_grad()\n","        output = model(src, tgt)  # 여기서 tgt를 전체 시퀀스로 전달합니다.\n","        output_dim = output.shape[-1]\n","        output = output.view(-1, output_dim)\n","\n","\n","        tgt = tgt[:, 1:].reshape(-1)\n","\n","        loss = criterion(output, tgt)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","# 모델 학습\n","for epoch in range(N_EPOCHS):\n","    train_loss = train(model, train_loader, optimizer, criterion)\n","    print(f'Epoch: {epoch + 1}, Train Loss: {train_loss:.3f}')"],"metadata":{"id":"PG0EIjHFA1RN"},"execution_count":null,"outputs":[]}]}